<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lesson 11: Motion Detection</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <header class="lesson-header">
            <a href="main.html" class="back-btn">
                <i class="fas fa-arrow-left"></i>
                <span id="back-text">Back</span>
            </a>
            <h1 id="lesson11-full-title">Lesson 11: Motion Detection</h1>
        </header>
        
        <main class="lesson-content">
            <div class="explanation-box">
                <h2><i class="fas fa-running"></i> <span id="lesson11-concept-title">Seeing What Moves</span></h2>
                <p id="lesson11-concept-text">Security drones need to detect moving objects - people, animals, or vehicles. Motion detection finds changes between frames. This is how drones spot intruders or wildlife!</p>
                
                <div class="motion-methods">
                    <div class="motion-item">
                        <div class="motion-icon frame-diff"></div>
                        <h3>Frame Difference</h3>
                        <p id="frame-diff-text">Simple: Compare current frame with previous</p>
                    </div>
                    <div class="motion-item">
                        <div class="motion-icon background"></div>
                        <h3>Background Subtraction</h3>
                        <p id="background-text">Smart: Learn background, detect foreground changes</p>
                    </div>
                    <div class="motion-item">
                        <div class="motion-icon optical"></div>
                        <h3>Optical Flow</h3>
                        <p id="optical-text">Advanced: Track movement direction and speed</p>
                    </div>
                </div>
                
                <h2><i class="fas fa-list"></i> <span id="lesson11-commands-title">Motion Detection Commands</span></h2>
                <div class="commands-list">
                    <div class="command-item">
                        <code>cv2.absdiff(frame1, frame2)</code>
                        <p id="absdiff-text">Absolute difference between two frames.</p>
                    </div>
                    
                    <div class="command-item">
                        <code>cv2.createBackgroundSubtractorMOG2()</code>
                        <p id="mog2-text">Creates background subtractor (most common method).</p>
                    </div>
                    
                    <div class="command-item">
                        <code>cv2.calcOpticalFlowFarneback()</code>
                        <p id="opticalflow-text">Calculates dense optical flow (movement vectors).</p>
                    </div>
                    
                    <div class="command-item">
                        <code>cv2.findContours()</code>
                        <p id="motion-contours-text">Find contours in motion mask to get moving objects.</p>
                    </div>
                </div>
                
                <h2><i class="fas fa-code"></i> <span id="lesson11-example-title">Drone Security System</span></h2>
                <div class="code-block">
                    <pre><code># Drone Security System - Motion Detection
import cv2
import numpy as np
import time
from datetime import datetime

print("=== Drone Security System ===")
print("Mission: Detect moving objects for security monitoring")

class DroneMotionDetector:
    def __init__(self, method='mog2', sensitivity=500):
        """
        Initialize motion detector
        method: 'frame_diff', 'mog2', or 'optical_flow'
        sensitivity: Minimum area to consider as motion
        """
        self.method = method
        self.sensitivity = sensitivity
        self.prev_frame = None
        self.prev_gray = None
        
        if method == 'mog2':
            self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(
                history=500, varThreshold=16, detectShadows=True
            )
            print("Using MOG2 background subtraction")
        elif method == 'optical_flow':
            print("Using optical flow method")
        else:
            print("Using frame difference method")
        
        self.motion_log = []
        self.alert_count = 0
        
    def detect_motion_frame_diff(self, frame):
        """Simple frame difference method"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (21, 21), 0)
        
        if self.prev_frame is None:
            self.prev_frame = gray
            return frame, np.zeros(gray.shape, dtype=np.uint8), 0
        
        # Compute difference between current and previous frame
        frame_diff = cv2.absdiff(self.prev_frame, gray)
        
        # Apply threshold
        _, thresh = cv2.threshold(frame_diff, 25, 255, cv2.THRESH_BINARY)
        
        # Dilate to fill holes
        thresh = cv2.dilate(thresh, None, iterations=2)
        
        self.prev_frame = gray
        
        return thresh
    
    def detect_motion_mog2(self, frame):
        """MOG2 background subtraction method"""
        # Apply background subtraction
        fg_mask = self.bg_subtractor.apply(frame)
        
        # Remove shadows (value 127 in MOG2)
        _, fg_mask = cv2.threshold(fg_mask, 200, 255, cv2.THRESH_BINARY)
        
        # Clean up mask
        kernel = np.ones((5,5), np.uint8)
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)
        fg_mask = cv2.dilate(fg_mask, kernel, iterations=2)
        
        return fg_mask
    
    def detect_motion_optical_flow(self, frame):
        """Optical flow method (dense)"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        if self.prev_gray is None:
            self.prev_gray = gray
            return np.zeros(gray.shape, dtype=np.uint8)
        
        # Calculate optical flow
        flow = cv2.calcOpticalFlowFarneback(
            self.prev_gray, gray, None,
            0.5, 3, 15, 3, 5, 1.2, 0
        )
        
        # Convert flow to magnitude and angle
        magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])
        
        # Create mask based on magnitude
        mask = np.zeros_like(gray)
        mask[magnitude > 2] = 255
        
        self.prev_gray = gray
        
        return mask
    
    def process_frame(self, frame):
        """Process single frame for motion detection"""
        # Get motion mask based on selected method
        if self.method == 'frame_diff':
            motion_mask = self.detect_motion_frame_diff(frame)
        elif self.method == 'mog2':
            motion_mask = self.detect_motion_mog2(frame)
        elif self.method == 'optical_flow':
            motion_mask = self.detect_motion_optical_flow(frame)
        else:
            motion_mask = np.zeros(frame.shape[:2], dtype=np.uint8)
        
        # Find contours in motion mask
        contours, _ = cv2.findContours(motion_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Create result frame
        result = frame.copy()
        motion_detected = False
        motion_areas = []
        
        # Process each contour
        for contour in contours:
            area = cv2.contourArea(contour)
            
            if area > self.sensitivity:
                motion_detected = True
                
                # Get bounding box
                x, y, w, h = cv2.boundingRect(contour)
                motion_areas.append((x, y, w, h, area))
                
                # Draw bounding box
                cv2.rectangle(result, (x, y), (x+w, y+h), (0, 0, 255), 2)
                cv2.putText(result, 'MOTION', (x, y-10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                
                # Draw contour
                cv2.drawContours(result, [contour], 0, (0, 255, 0), 2)
        
        # Log motion if detected
        if motion_detected:
            self.log_motion(motion_areas)
        
        return result, motion_mask, motion_detected, motion_areas
    
    def log_motion(self, motion_areas):
        """Log motion detection event"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        total_area = sum(area for _, _, _, _, area in motion_areas)
        num_objects = len(motion_areas)
        
        log_entry = {
            'timestamp': timestamp,
            'num_objects': num_objects,
            'total_area': total_area,
            'areas': motion_areas
        }
        
        self.motion_log.append(log_entry)
        self.alert_count += 1
        
        print(f"[ALERT {self.alert_count}] Motion detected: {num_objects} object(s), area: {total_area}")
    
    def get_stats(self):
        """Get motion detection statistics"""
        return {
            'total_alerts': self.alert_count,
            'recent_log': self.motion_log[-5:] if self.motion_log else []
        }

def simulate_drone_security():
    """Simulate drone security monitoring"""
    print("\n=== Security Monitoring Simulation ===")
    print("Simulating drone camera feed with moving objects...")
    
    # Create initial scene (park with trees)
    width, height = 640, 480
    scene = np.zeros((height, width, 3), dtype=np.uint8)
    
    # Create park background
    scene[:] = [100, 150, 50]  # Grass
    
    # Add trees (static)
    for i in range(5):
        x = 100 + i * 100
        y = 200
        cv2.circle(scene, (x, y), 30, (0, 100, 0), -1)
        cv2.rectangle(scene, (x-10, y), (x+10, y+50), (50, 30, 10), -1)
    
    # Add path
    cv2.rectangle(scene, (0, 350), (width, 450), (150, 150, 150), -1)
    
    # Create moving objects (people, cars)
    moving_objects = []
    
    # Add some initial objects
    moving_objects.append({
        'type': 'person',
        'x': 50,
        'y': 380,
        'dx': 3,
        'dy': 0,
        'size': 20,
        'color': (200, 100, 100)
    })
    
    moving_objects.append({
        'type': 'car',
        'x': 400,
        'y': 380,
        'dx': -2,
        'dy': 0,
        'size': 40,
        'color': (100, 100, 200)
    })
    
    # Initialize motion detector
    print("\nInitializing motion detector...")
    detector = DroneMotionDetector(method='mog2', sensitivity=300)
    
    # Create display windows
    cv2.namedWindow('Drone Security Feed', cv2.WINDOW_NORMAL)
    cv2.namedWindow('Motion Mask', cv2.WINDOW_NORMAL)
    
    frame_count = 0
    motion_history = []
    
    print("\n=== Starting Security Monitor ===")
    print("Press 'q' to quit")
    print("Press '1', '2', '3' to switch methods")
    print("  '1': Frame Difference")
    print("  '2': MOG2 (default)")
    print("  '3': Optical Flow")
    
    while True:
        # Update scene
        current_scene = scene.copy()
        
        # Update and draw moving objects
        for obj in moving_objects:
            # Move object
            obj['x'] += obj['dx']
            obj['y'] += obj['dy']
            
            # Bounce at edges
            if obj['x'] < 0 or obj['x'] > width:
                obj['dx'] = -obj['dx']
            if obj['y'] < 300 or obj['y'] > 450:
                obj['dy'] = -obj['dy']
            
            # Draw object
            if obj['type'] == 'person':
                # Draw person (circle for head, rectangle for body)
                cv2.circle(current_scene, (obj['x'], obj['y']-10), 8, obj['color'], -1)
                cv2.rectangle(current_scene, 
                            (obj['x']-5, obj['y']), 
                            (obj['x']+5, obj['y']+20), 
                            obj['color'], -1)
            elif obj['type'] == 'car':
                # Draw car (rectangle)
                cv2.rectangle(current_scene,
                            (obj['x']-obj['size'], obj['y']-10),
                            (obj['x']+obj['size'], obj['y']+10),
                            obj['color'], -1)
                # Wheels
                cv2.circle(current_scene, (obj['x']-obj['size']+10, obj['y']+10), 8, (0, 0, 0), -1)
                cv2.circle(current_scene, (obj['x']+obj['size']-10, obj['y']+10), 8, (0, 0, 0), -1)
        
        # Occasionally add new objects
        if frame_count % 100 == 0 and len(moving_objects) < 5:
            new_type = 'person' if np.random.random() > 0.5 else 'car'
            new_obj = {
                'type': new_type,
                'x': np.random.randint(50, width-50),
                'y': 380,
                'dx': np.random.choice([-3, -2, 2, 3]),
                'dy': 0,
                'size': 20 if new_type == 'person' else 40,
                'color': (np.random.randint(100, 255), 
                         np.random.randint(100, 255), 
                         np.random.randint(100, 255))
            }
            moving_objects.append(new_obj)
            print(f"New {new_type} entered the scene")
        
        # Process frame for motion detection
        result, motion_mask, motion_detected, motion_areas = detector.process_frame(current_scene)
        
        # Add motion history visualization
        motion_history.append(1 if motion_detected else 0)
        if len(motion_history) > 100:
            motion_history.pop(0)
        
        # Add status overlay
        status_text = f"Motion: {'DETECTED' if motion_detected else 'CLEAR'}"
        status_color = (0, 0, 255) if motion_detected else (0, 255, 0)
        
        cv2.putText(result, status_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, status_color, 2)
        
        cv2.putText(result, f"Objects: {len(moving_objects)}", (10, 70),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        
        cv2.putText(result, f"Method: {detector.method}", (10, 100),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        
        cv2.putText(result, f"Alerts: {detector.alert_count}", (10, 130),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        
        # Draw motion history graph
        graph_height = 80
        graph_width = 200
        graph = np.zeros((graph_height, graph_width, 3), dtype=np.uint8)
        
        for i, motion in enumerate(motion_history[-graph_width:]):
            if motion:
                cv2.line(graph, (i, 0), (i, graph_height), (0, 0, 255), 1)
        
        # Add graph to result
        result[10:10+graph_height, width-graph_width-10:width-10] = graph
        
        # Display
        cv2.imshow('Drone Security Feed', result)
        cv2.imshow('Motion Mask', motion_mask)
        
        # Handle keyboard input
        key = cv2.waitKey(30) & 0xFF
        
        if key == ord('q'):
            break
        elif key == ord('1'):
            detector = DroneMotionDetector(method='frame_diff', sensitivity=300)
            print("Switched to Frame Difference method")
        elif key == ord('2'):
            detector = DroneMotionDetector(method='mog2', sensitivity=300)
            print("Switched to MOG2 method")
        elif key == ord('3'):
            detector = DroneMotionDetector(method='optical_flow', sensitivity=300)
            print("Switched to Optical Flow method")
        
        frame_count += 1
    
    # Show final statistics
    print("\n=== Monitoring Complete ===")
    stats = detector.get_stats()
    
    print(f"\nTotal frames processed: {frame_count}")
    print(f"Motion alerts: {stats['total_alerts']}")
    
    if stats['recent_log']:
        print("\nRecent motion events:")
        for log in stats['recent_log']:
            print(f"  {log['timestamp']}: {log['num_objects']} object(s)")
    
    cv2.destroyAllWindows()
    
    return detector

def real_drone_application():
    """Show real drone application examples"""
    print("\n" + "="*50)
    print("REAL DRONE MOTION DETECTION APPLICATIONS")
    print("="*50)
    
    print("\n1. SECURITY & SURVEILLANCE:")
    print("   • Perimeter monitoring")
    print("   • Intruder detection")
    print("   • Crowd monitoring")
    
    print("\n2. WILDLIFE MONITORING:")
    print("   • Animal movement tracking")
    print("   • Migration patterns")
    print("   • Poaching prevention")
    
    print("\n3. TRAFFIC MONITORING:")
    print("   • Vehicle counting")
    print("   • Accident detection")
    print("   • Traffic flow analysis")
    
    print("\n4. CONSTRUCTION SITE MONITORING:")
    print("   • Equipment tracking")
    print("   • Safety compliance")
    print("   • Progress monitoring")
    
    print("\nCode example for wildlife monitoring:")
    print("""
def wildlife_motion_detection():
    # Specialized for animal detection
    detector = DroneMotionDetector(method='mog2')
    
    while True:
        frame = drone_camera.get_frame()
        result, mask, detected, areas = detector.process_frame(frame)
        
        if detected:
            for x, y, w, h, area in areas:
                # Classify by size/shape
                if area > 5000:
                    label = "Large animal"
                elif area > 1000:
                    label = "Medium animal"
                else:
                    label = "Small animal/bird"
                
                cv2.putText(result, label, (x, y-10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)
        
        return result
    """)

# Main execution
if __name__ == "__main__":
    print("Starting Drone Motion Detection System...")
    
    # Run simulation
    detector = simulate_drone_security()
    
    # Show real applications
    real_drone_application()
    
    print("\n=== Motion Detection Complete ===")
    print("\nKey takeaways:")
    print("1. Frame difference: Simple but sensitive to camera movement")
    print("2. MOG2: Robust, handles lighting changes")
    print("3. Optical flow: Shows direction, but computationally heavy")
    
    print("\nFor stationary drones (security cameras): Use MOG2")
    print("For moving drones: Use frame difference with stabilization")
    
    print("\nPress Enter to exit...")
    input()
    
    print("\n=== Mission Complete ===")
    print("Your drone can now detect motion!")
    print("This enables security, wildlife monitoring, and traffic analysis")</code></pre>
                </div>
                
                <h2><i class="fas fa-keyboard"></i> <span id="lesson11-practice-title">Practice: Tune Sensitivity</span></h2>
                <div class="practice-area">
                    <textarea id="code-editor11" placeholder="Try adjusting sensitivity to detect only large movements..."></textarea>
                    <div class="practice-buttons">
                        <button class="btn-check" id="check-btn11">
                            <i class="fas fa-check"></i>
                            <span id="check-text">Check Code</span>
                        </button>
                        <button class="btn-clear" id="clear-btn11">
                            <i class="fas fa-eraser"></i>
                            <span id="clear-text">Clear</span>
                        </button>
                    </div>
                    <div id="feedback-message11"></div>
                </div>
                
                <div class="real-life-example">
                    <h3><i class="fas fa-shield-alt"></i> <span id="lesson11-real-title">Border Patrol Drones:</span></h3>
                    <p id="lesson11-real-text">US border patrol drones use motion detection to spot illegal crossings. Wildlife conservation drones monitor animal movements without human presence. Your drone could guard your property!</p>
                </div>
            </div>
            
            <div class="next-lesson">
                <a href="lesson10.html" class="btn-prev">
                    <i class="fas fa-arrow-left"></i>
                    <span id="prev-text">Previous Lesson</span>
                </a>
                <a href="lesson12.html" class="btn-next">
                    <span id="next-text">Next: Path Planning</span>
                    <i class="fas fa-arrow-right"></i>
                </a>
            </div>
        </main>
        
        <footer class="footer">
            <button class="btn-change-lang" onclick="window.location.href='index.html'">
                <i class="fas fa-globe"></i>
                <span id="change-lang-text">Change Language</span>
            </button>
            <p></p>
            <p>© Olha Bondarieva</p>
            <p>© Mykhailo Bondariev-Hapon</p>
        </footer>
    </div>
    
    <script src="lang.js"></script>
    <script src="script.js"></script>
    <style>
        .motion-methods {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .motion-item {
            text-align: center;
            padding: 20px;
            background: var(--beige);
            border-radius: 10px;
        }
        
        .motion-icon {
            width: 100px;
            height: 100px;
            margin: 0 auto 15px;
            border: 2px solid var(--primary-green);
            border-radius: 10px;
            position: relative;
        }
        
        .motion-icon.frame-diff::before {
            content: '';
            position: absolute;
            width: 80px;
            height: 80px;
            border: 2px solid #000;
            background: #fff;
            top: 10px;
            left: 10px;
            animation: pulse 2s infinite;
        }
        
        .motion-icon.background::before {
            content: '';
            position: absolute;
            width: 60px;
            height: 60px;
            background: #fff;
            border: 2px solid #000;
            top: 20px;
            left: 20px;
        }
        
        .motion-icon.background::after {
            content: '';
            position: absolute;
            width: 40px;
            height: 40px;
            background: #f00;
            top: 30px;
            left: 30px;
            animation: move 3s infinite alternate;
        }
        
        .motion-icon.optical::before {
            content: '';
            position: absolute;
            width: 80px;
            height: 80px;
            background: 
                repeating-linear-gradient(
                    45deg,
                    transparent,
                    transparent 10px,
                    #000 10px,
                    #000 20px
                );
            top: 10px;
            left: 10px;
        }
        
        @keyframes pulse {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(0.9); opacity: 0.7; }
        }
        
        @keyframes move {
            0% { transform: translateX(0); }
            100% { transform: translateX(20px); }
        }
    </style>
    <script>
        // Добавляем переводы для урока 11
        if (!translations.en['lesson11-full-title']) {
            Object.assign(translations.en, {
                'lesson11-full-title': 'Lesson 11: Motion Detection',
                'lesson11-concept-title': 'Seeing What Moves',
                'lesson11-concept-text': 'Security drones need to detect moving objects - people, animals, or vehicles. Motion detection finds changes between frames. This is how drones spot intruders or wildlife!',
                'frame-diff-text': 'Simple: Compare current frame with previous',
                'background-text': 'Smart: Learn background, detect foreground changes',
                'optical-text': 'Advanced: Track movement direction and speed',
                'lesson11-commands-title': 'Motion Detection Commands',
                'absdiff-text': 'Absolute difference between two frames.',
                'mog2-text': 'Creates background subtractor (most common method).',
                'opticalflow-text': 'Calculates dense optical flow (movement vectors).',
                'motion-contours-text': 'Find contours in motion mask to get moving objects.',
                'lesson11-example-title': 'Drone Security System',
                'lesson11-practice-title': 'Practice: Tune Sensitivity',
                'lesson11-real-title': 'Border Patrol Drones:',
                'lesson11-real-text': 'US border patrol drones use motion detection to spot illegal crossings. Wildlife conservation drones monitor animal movements without human presence. Your drone could guard your property!'
            });

            Object.assign(translations.de, {
                'lesson11-full-title': 'Lektion 11: Bewegungs-erkennung',
                'lesson11-concept-title': 'Sehen, was sich bewegt',
                'lesson11-concept-text': 'Sicherheitsdrohnen müssen bewegte Objekte erkennen - Menschen, Tiere oder Fahrzeuge. Bewegungserkennung findet Veränderungen zwischen Bildern. So bemerken Drohnen Eindringlinge oder Wildtiere!',
                'frame-diff-text': 'Einfach: Aktuelles Bild mit vorherigem vergleichen',
                'background-text': 'Intelligent: Hintergrund lernen, Vordergrundveränderungen erkennen',
                'optical-text': 'Fortschrittlich: Bewegungsrichtung und Geschwindigkeit verfolgen',
                'lesson11-commands-title': 'Bewegungserkennungs-Commands',
                'absdiff-text': 'Absolute Differenz zwischen zwei Bildern.',
                'mog2-text': 'Erstellt Hintergrund-Subtraktor (häufigste Methode).',
                'opticalflow-text': 'Berechnet dichten optischen Fluss (Bewegungsvektoren).',
                'motion-contours-text': 'Finde Konturen in Bewegungsmaske, um bewegte Objekte zu erhalten.',
                'lesson11-example-title': 'Drohnen-Sicherheitssystem',
                'lesson11-practice-title': 'Übung: Empfindlichkeit einstellen',
                'lesson11-real-title': 'Grenzpatrouillen-Drohnen:',
                'lesson11-real-text': 'US-Grenzpatrouillen nutzen Bewegungserkennung, um illegale Grenzübertritte zu bemerken. Wildtierschutz-Drohnen überwachen Tierbewegungen ohne menschliche Anwesenheit. Deine Drohne könnte dein Eigentum bewachen!'
            });

            Object.assign(translations.ru, {
                'lesson11-full-title': 'Урок 11: Обнаружение движения',
                'lesson11-concept-title': 'Видеть, что движется',
                'lesson11-concept-text': 'Охранным дронам нужно обнаруживать движущиеся объекты - людей, животных или транспорт. Обнаружение движения находит изменения между кадрами. Так дроны замечают нарушителей или диких животных!',
                'frame-diff-text': 'Простое: Сравнить текущий кадр с предыдущим',
                'background-text': 'Умное: Изучить фон, обнаружить изменения на переднем плане',
                'optical-text': 'Продвинутое: Отслеживать направление и скорость движения',
                'lesson11-commands-title': 'Команды обнаружения движения',
                'absdiff-text': 'Абсолютная разница между двумя кадрами.',
                'mog2-text': 'Создаёт вычитатель фона (самый частый метод).',
                'opticalflow-text': 'Вычисляет плотный оптический поток (векторы движения).',
                'motion-contours-text': 'Найти контуры в маске движения, чтобы получить движущиеся объекты.',
                'lesson11-example-title': 'Охранная система для дрона',
                'lesson11-practice-title': 'Практика: Настроить чувствительность',
                'lesson11-real-title': 'Дроны пограничного контроля:',
                'lesson11-real-text': 'Дроны пограничного контроля США используют обнаружение движения, чтобы замечать нелегальные переходы. Дроны для охраны дикой природы следят за передвижениями животных без присутствия человека. Твой дрон мог бы охранять твою собственность!'
            });
        }
        
        document.getElementById('check-btn11')?.addEventListener('click', function() {
            const code = document.getElementById('code-editor11').value;
            const feedback = document.getElementById('feedback-message11');
            
            if (code.includes('sensitivity') || code.includes('threshold')) {
                feedback.innerHTML = '<i class="fas fa-check-circle success"></i> Perfect! Sensitivity tuning prevents false alarms!';
                feedback.className = 'feedback success';
            } else if (code.includes('cv2.absdiff') || code.includes('createBackgroundSubtractor')) {
                feedback.innerHTML = '<i class="fas fa-exclamation-circle partial"></i> Good motion detection! Now add sensitivity control.';
                feedback.className = 'feedback partial';
            } else {
                feedback.innerHTML = '<i class="fas fa-times-circle error"></i> Try adjusting the sensitivity/threshold parameter.';
                feedback.className = 'feedback error';
            }
        });
        
        document.getElementById('clear-btn11')?.addEventListener('click', function() {
            document.getElementById('code-editor11').value = '';
            document.getElementById('feedback-message11').innerHTML = '';
            document.getElementById('feedback-message11').className = 'feedback';
        });
    </script>
    <script>
        // Отмечаем урок 11 как пройденный
        markLessonComplete(11);
    </script>
</body>
</html>
